{
 "metadata": {
  "name": "",
  "signature": "sha256:709320bafd3aa6006c0563b0663f9707a89659a6e5e00141fa93d0f025c514e6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Genome-wide association study (GWAS)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook demonstrates conducting a genome-wide association study using the public 1000 Genomes dataset stored in BigQuery.\n",
      "\n",
      "### In this notebook you will\n",
      "* Explore the 1000 Genomes dataset available in BigQuery\n",
      "* Use the `%%sql` statement to write and execute SQL statements within the notebook\n",
      "* Extract data from BigQuery and create a local dataset that can be manipulated in Python for visualization and further analysis\n",
      "\n",
      "Related Links:\n",
      "* [BigQuery](https://cloud.google.com/bigquery/)\n",
      "* BigQuery [SQL reference](https://cloud.google.com/bigquery/query-reference)\n",
      "* [1,000 Genomes Data Description](http://googlegenomics.readthedocs.org/en/latest/use_cases/discover_public_data/1000_genomes.html)\n",
      "* This notebook is based on the [Google Genomics](https://cloud.google.com/genomics/) BigQuery examples:\n",
      "    * [GWAS Chi-squared Test](https://github.com/googlegenomics/bigquery-examples/blob/master/1000genomes/sql/gwas-pattern-chi-squared-test.sql)\n",
      "    * [GWAS z-test](https://github.com/googlegenomics/bigquery-examples/blob/master/1000genomes/sql/gwas-pattern-two-proportion-z-test.sql)\n",
      "----"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Experiment design and dataset construction"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this experiment, we'll be identifying variant positions within chromosome 12 that differ significantly between the case and control groups. The case group for the purposes of this notebook will be individuals from the \"EAS\" (East Asian) super population.\n",
      "\n",
      "To work with genomics data stored within BigQuery, we'll import the gcp.bigquery library, which provides a set of high-level wrappers for manipulating SQL within the notebook, issuing queries to BigQuery and translating result sets into Pandas dataframes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import gcp.bigquery as bq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Table selection and summary"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Variant data from the 1000 genomes dataset is publicly accessible within BigQuery. We can view the schema for the variants table via the gcp.bigquery library."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "variants_table = bq.table('genomics-public-data:1000_genomes.variants')\n",
      "variants_table.schema"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Classifying per-call variant positions into variant/non-variant groups"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can tally the reference/alternate allele accounts for *individual* variant positions within chromosome 12. The field `call.genotype` is an integer ranging from `[0, num_alternate_bases]`. A value of zero indicates that the genotype for the call is the same as the reference (i.e., non-variant). A value of 1 would indicate that the genotype for the call is the 1st value in the list of alternate bases (likewise for values >1)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%sql --name allele_counts\n",
      "\n",
      "SELECT \n",
      "    reference_name,\n",
      "    start,\n",
      "    reference_bases,\n",
      "    alternate_bases,\n",
      "    end,\n",
      "    vt,    \n",
      "    call.call_set_name AS call_set_name,\n",
      "    (0 = first_allele) + (0 = second_allele) AS ref_count,\n",
      "    (1 = first_allele) + (1 = second_allele) AS alt_count,    \n",
      "FROM\n",
      "  FLATTEN((\n",
      "    SELECT\n",
      "      reference_name,\n",
      "      start,\n",
      "      reference_bases,\n",
      "      alternate_bases,\n",
      "      end,\n",
      "      vt,\n",
      "      call.call_set_name,\n",
      "      NTH(1, call.genotype) WITHIN call AS first_allele,\n",
      "      NTH(2, call.genotype) WITHIN call AS second_allele,\n",
      "    FROM\n",
      "      $variants_table\n",
      "    WHERE\n",
      "      reference_name = '12' -- i.e., chromosome 12\n",
      "    HAVING\n",
      "      -- Exclude calls _where one _or both alleles were NOT called (-1)\n",
      "      0 <= first_allele\n",
      "      AND 0 <= second_allele\n",
      "    ),\n",
      "    call)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's verify that our allele counts match our expectations before moving on. For any given row, the alternate + reference counts should sum to 2 for this experiment."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bq.query(allele_counts, {\"variants_table\":variants_table}).sample()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Assigning case and control groups"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can join our allele counts with metadata available in the sample info table. We'll use this sample metadata to split the set of genomes into case and control groups based upon the super population group."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample_info_table = bq.table('genomics-public-data:1000_genomes.sample_info')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%sql --name exp_groups\n",
      "\n",
      "SELECT\n",
      "  super_population\n",
      "  , IF('EAS' = super_population, TRUE, FALSE) AS is_case\n",
      "  , call_set_name\n",
      "  , reference_name\n",
      "  , start\n",
      "  , reference_bases\n",
      "  , alternate_bases\n",
      "  , end\n",
      "  , vt\n",
      "  , ref_count\n",
      "  , alt_count\n",
      "FROM $allele_counts AS allele_counts\n",
      "JOIN $sample_info_table AS samples\n",
      "  ON allele_counts.call_set_name = samples.sample"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bq.query(exp_groups, {\"allele_counts\":allele_counts,\n",
      "                      \"sample_info_table\":sample_info_table,\n",
      "                      \"variants_table\":variants_table}).sample()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The variants table contains a few different types of variant: structural variants (\"SV\"), indels (\"INDEL\") and SNPs (\"SNP\")."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%sql\n",
      "SELECT \n",
      "  vt,\n",
      "  COUNT(*)\n",
      "FROM $exp_groups\n",
      "GROUP BY vt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For the purposes of this experiment, let's limit the variants to only SNPs."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%sql --name snps\n",
      "SELECT * \n",
      "FROM $exp_groups\n",
      "WHERE vt='SNP'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "snps.sample()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Tallying reference/alternate allele counts for case/control groups"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we've assigned each call set to either the case or the control group, we can tally up the counts of reference and alternate alleles within each of our assigned case/control groups, for each variant position, like so:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%sql --name grouped_counts\n",
      "\n",
      "SELECT\n",
      "    reference_name,\n",
      "    start,\n",
      "    end,\n",
      "    reference_bases,\n",
      "    alternate_bases,\n",
      "    vt,\n",
      "\n",
      "    SUM(ref_count + alt_count) AS allele_count,\n",
      "    SUM(ref_count) AS ref_count,\n",
      "    SUM(alt_count) AS alt_count,\n",
      "    SUM(IF(TRUE = is_case,\n",
      "        INTEGER(ref_count + alt_count),\n",
      "        0)) AS case_count,\n",
      "    SUM(IF(FALSE = is_case,\n",
      "        INTEGER(ref_count + alt_count),\n",
      "        0)) AS control_count,\n",
      "    SUM(IF(TRUE = is_case,\n",
      "        ref_count,\n",
      "        0)) AS case_ref_count,\n",
      "    SUM(IF(TRUE = is_case,\n",
      "        alt_count,\n",
      "        0)) AS case_alt_count,\n",
      "    SUM(IF(FALSE = is_case,\n",
      "        ref_count,\n",
      "        0)) AS control_ref_count,\n",
      "    SUM(IF(FALSE = is_case,\n",
      "        alt_count,\n",
      "        0)) AS control_alt_count\n",
      "FROM $snps\n",
      "GROUP BY\n",
      "    reference_name,\n",
      "    start,\n",
      "    end,\n",
      "    reference_bases,\n",
      "    alternate_bases,\n",
      "    vt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print grouped_counts.sql"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Again, validate that the results are sensical for the group level counts (still per variant position)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bq.query(grouped_counts, {\"snps\":snps,\n",
      "                          \"exp_groups\":exp_groups,\n",
      "                          \"allele_counts\":allele_counts,\n",
      "                          \"sample_info_table\":sample_info_table,\n",
      "                          \"variants_table\":variants_table}).sample()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Quantify the statistical significance at each variant positions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can quantify the statistical significance of each variant position using the Chi-squared test. Furthermore, we can restrict our result set to *only* statistically significant variant positions for this experiment by ranking each position by its statistical signficance (decreasing) and thresholding the results for significance at `p <= 5e-8` (chi-squared score >= 29.7)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%sql --name results\n",
      "\n",
      "SELECT\n",
      "  reference_name,\n",
      "  start,\n",
      "  end,\n",
      "  reference_bases,\n",
      "  alternate_bases,\n",
      "  vt,\n",
      "  case_count,\n",
      "  control_count,\n",
      "  allele_count,\n",
      "  ref_count,\n",
      "  alt_count,\n",
      "  case_ref_count,\n",
      "  case_alt_count,\n",
      "  control_ref_count,\n",
      "  control_alt_count,\n",
      "  ROUND(\n",
      "    POW(case_ref_count - (ref_count/allele_count)*case_count,\n",
      "      2)/((ref_count/allele_count)*case_count) +\n",
      "    POW(control_ref_count - (ref_count/allele_count)*control_count,\n",
      "      2)/((ref_count/allele_count)*control_count) +\n",
      "    POW(case_alt_count - (alt_count/allele_count)*case_count,\n",
      "      2)/((alt_count/allele_count)*case_count) +\n",
      "    POW(control_alt_count - (alt_count/allele_count)*control_count,\n",
      "      2)/((alt_count/allele_count)*control_count),\n",
      "    3)\n",
      "  AS chi_squared_score\n",
      "FROM $grouped_counts\n",
      "WHERE\n",
      "  # For chi-squared, expected counts must be at least 5 for each group\n",
      "  (ref_count/allele_count)*case_count >= 5.0\n",
      "  AND (ref_count/allele_count)*control_count >= 5.0\n",
      "  AND (alt_count/allele_count)*case_count >= 5.0\n",
      "  AND (alt_count/allele_count)*control_count >= 5.0\n",
      "HAVING\n",
      "  # Chi-squared critical value for df=1, p-value=5*10^-8 is 29.71679\n",
      "  chi_squared_score >= 29.71679\n",
      "ORDER BY\n",
      "  chi_squared_score DESC,\n",
      "  allele_count DESC"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A quick sanity check of the results reveals that the positions deemed significant do in fact have significantly different case/control counts for the alternate/reference bases."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bq.query(results, {\"grouped_counts\":grouped_counts,\n",
      "                   \"snps\":snps,\n",
      "                   \"exp_groups\":exp_groups,\n",
      "                   \"allele_counts\":allele_counts,\n",
      "                   \"sample_info_table\":sample_info_table,\n",
      "                   \"variants_table\":variants_table}).sample()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Computing Chi-squared statistics in BigQuery vs Python vs R"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's compare these BigQuery-computed Chi-squared scores to ones calculated via Python's statistical packages"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from scipy.stats import chi2_contingency\n",
      "\n",
      "chi2, p, dof, expected = chi2_contingency(np.array([ \n",
      "    [220, 352], # case \n",
      "    [1593, 19]  # control\n",
      "]))\n",
      "\n",
      "print 'Python Chi-sq score = %.3f' % chi2\n",
      "print 'BigQuery was 1090.781'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Comparing Python statistics to those computed in R\n",
      "```\n",
      "> chisq.test(rbind(c(220, 352), c(1593, 19)))\n",
      "\n",
      "\tPearson's Chi-squared test with Yates' continuity correction\n",
      "\n",
      "data:  rbind(c(220, 352), c(1593, 19))\n",
      "X-squared = 1086.505, df = 1, p-value < 2.2e-16\n",
      "```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%sql --name top1k_snps\n",
      "SELECT\n",
      "  chi_squared_score\n",
      "  , control_ref_count \n",
      "  , control_alt_count \n",
      "  , case_ref_count\n",
      "  , case_alt_count\n",
      "FROM $results\n",
      "LIMIT 1000"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chisq_df = bq.query(top1k_snps, {\"results\":results,\n",
      "                                 \"grouped_counts\":grouped_counts,\n",
      "                                 \"snps\":snps,\n",
      "                                 \"exp_groups\":exp_groups,\n",
      "                                 \"allele_counts\":allele_counts,\n",
      "                                 \"sample_info_table\":sample_info_table,\n",
      "                                 \"variants_table\":variants_table}).to_dataframe()\n",
      "chisq_df.shape\n",
      "chisq_df.ix[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in xrange(len(chisq_df)):\n",
      "    # construct a contingency table for the reference/alternate allele counts\n",
      "    ctable = np.array([\n",
      "        [chisq_df.ix[i]['case_ref_count'],    chisq_df.ix[i]['case_alt_count']],\n",
      "        [chisq_df.ix[i]['control_ref_count'], chisq_df.ix[i]['control_alt_count']]])\n",
      "    \n",
      "    py_chi2, pvalue, dof, expected = chi2_contingency(ctable)\n",
      "    bq_chi2 = chisq_df.ix[i]['chi_squared_score']\n",
      "    print 'BQ: %.3f, SciPy: %.3f: delta=%.3f' % (bq_chi2, py_chi2, abs(bq_chi2 - py_chi2))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Analyzing the GWAS results"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, how many statistically significant variant positions did we find?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%sql \n",
      "SELECT COUNT(*) AS num_significant_snps\n",
      "FROM $results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We now have a dataset that is sufficiently small to fit into memory on our instance, so let's pull the top 1000 SNP positions locally. Since we only need a subset of the columns, we can project our data first to remove unneeded columns."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%sql --name sig_snps_dataset\n",
      "SELECT * FROM (\n",
      "    SELECT\n",
      "      reference_name\n",
      "      , start\n",
      "      , reference_bases\n",
      "      , alternate_bases\n",
      "      , chi_squared_score\n",
      "    FROM $results\n",
      "    LIMIT 1000\n",
      ")\n",
      "ORDER BY start asc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sig_snps = bq.query(sig_snps_dataset, {\"results\":results,\n",
      "                                       \"grouped_counts\":grouped_counts,\n",
      "                                       \"snps\":snps,\n",
      "                                       \"exp_groups\":exp_groups,\n",
      "                                       \"allele_counts\":allele_counts,\n",
      "                                       \"sample_info_table\":sample_info_table,\n",
      "                                       \"variants_table\":variants_table}).to_dataframe()\n",
      "sig_snps[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's visualize the distribution of significant SNPs along the length of the chromosome. The y-value of the charts indicates the Chi-squared score: larger values are more significant."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "\n",
      "#g = sns.distplot(sig_snps['start'], rug=False, hist=False, kde_kws=dict(bw=0.1))\n",
      "fig, ax = plt.subplots()\n",
      "ax.scatter(sig_snps['start'], sig_snps['chi_squared_score'], alpha=0.3, c='red')\n",
      "ax.set_ylabel('Chi-squared score')\n",
      "ax.set_xlabel('SNP position (bp)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's zoom in on one region that contains a large number of very significant SNPs:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots()\n",
      "ax.scatter(sig_snps['start'], sig_snps['chi_squared_score'], alpha=0.5, c='red')\n",
      "ax.set_xlim([3.3e7, 3.5e7])\n",
      "ax.set_ylabel('Chi-squared score')\n",
      "ax.set_xlabel('SNP position (bp)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Further exploration of statistically significant variant positions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can take our analysis further by mapping selected variant positions back to the chromosome and visualizing call sets and reads. Let's retrieve the top SNP identified when ranked by the Chi-squared score:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%sql --name top_snp\n",
      "SELECT start\n",
      "FROM $sig_snps_dataset\n",
      "ORDER BY chi_squared_score desc\n",
      "LIMIT 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bq.query(top_snp, {\"sig_snps_dataset\":sig_snps_dataset,\n",
      "                   \"results\":results,\n",
      "                   \"grouped_counts\":grouped_counts,\n",
      "                   \"snps\":snps,\n",
      "                   \"exp_groups\":exp_groups,\n",
      "                   \"allele_counts\":allele_counts,\n",
      "                   \"sample_info_table\":sample_info_table,\n",
      "                   \"variants_table\":variants_table}).results()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Grab an arbitrary set of 10 callset IDs for rendering in the genome browser."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%sql --name callset_ids\n",
      "SELECT * FROM (\n",
      "  SELECT call.call_set_id AS callset_id\n",
      "  FROM $variants_table\n",
      "  GROUP BY callset_id)\n",
      "LIMIT 10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "callsets_df = bq.query(callset_ids, {\"variants_table\":variants_table}).to_dataframe()\n",
      "callsets = list(callsets_df['callset_id'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO: move this to some library function\n",
      "from IPython.display import HTML\n",
      "def gabrowse(dataset, reference_name, start_position, callset_ids):\n",
      "    callsets_query_params = ''.join('&callsetId=%s&cBackend=GOOGLE' % callset_id for callset_id in callset_ids)\n",
      "    url = ('https://gabrowse.appspot.com/#=&backend=GOOGLE&location=12%3A'\n",
      "         + str(start_position)\n",
      "         + callsets_query_params)\n",
      "    return HTML('<iframe src=\"%s\" width=1024 height=800></iframe>' % url)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can render the call sets and reads for the selected SNP position by embedding the GABrowse application directly in our notebook."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gabrowse('1000genomes', '12', 110571373, callsets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Summary"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook illustrated how to conduct a GWAS experiment using variant data stored within the Google Genomics BigQuery tables, retrieve a local copy of the top results and visualize the data with Python libraries."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}