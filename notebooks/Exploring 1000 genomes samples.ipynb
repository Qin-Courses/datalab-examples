{
 "metadata": {
  "name": "",
  "signature": "sha256:1eb9288fecf79c9e710bc971adf5aec4f87307b1fb087f241b823edd57283f3f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Exploring the 1000 Genomes dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook demonstrates exploring the public 1000 Genomes dataset stored in BigQuery.\n",
      "\n",
      "### In this notebook you will\n",
      "* Explore the 1000 Genomes dataset available in BigQuery\n",
      "* Use the `%%sql` statement to write and execute SQL statements within the notebook\n",
      "* Extract data from BigQuery and create a local dataset that can be manipulated in Python\n",
      "* Refine and pivot your local dataset via the Pandas Python library\n",
      "* Visualize different aspects of your dataset via the Matplotlib and Seaborn Python libraries\n",
      "\n",
      "Related Links:\n",
      "* [BigQuery](https://cloud.google.com/bigquery/)\n",
      "* BigQuery [SQL reference](https://cloud.google.com/bigquery/query-reference)\n",
      "* [1,000 Genomes Data Description](http://googlegenomics.readthedocs.org/en/latest/use_cases/discover_public_data/1000_genomes.html)\n",
      "* This notebook is based on the [Google Genomics](https://cloud.google.com/genomics/) BigQuery example [Exploring the Phenotypic Data](https://github.com/googlegenomics/bigquery-examples/tree/master/1000genomes/data-stories/exploring-the-phenotypic-data)\n",
      "\n",
      "----"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Installing ad-hoc dependencies"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!pip install seaborn"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Working with data in BigQuery"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First let's take a look at the [1000 Genomes](http://www.1000genomes.org/) sample dataset table. We can use the `gcp.bigquery` Python package to fetch the table schema."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import gcp.bigquery as bq\n",
      "samples_table = bq.table('genomics-public-data:1000_genomes.sample_info')\n",
      "samples_table.schema"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see in the table schema that a number of different annotations exist for each genomic sample. To get a feel for the dataset, let's see how the samples are distributed across populations and super populations.\n",
      "\n",
      "The `%%bigquery sql` statement allows us to write SQL within our notebook and execute it within BigQuery. In the query below, we'll refer to our previously defined `samples_table` Python variable as `$samples_table`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%sql --name pops\n",
      "SELECT\n",
      "  population,\n",
      "  population_description,\n",
      "  super_population,\n",
      "  super_population_description,\n",
      "  COUNT(population) AS population_count,\n",
      "FROM\n",
      "  $samples_table\n",
      "GROUP BY\n",
      "  population,\n",
      "  population_description,\n",
      "  super_population,\n",
      "  super_population_description"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We've just defined the query so far, nothing has been executed yet. We can refer to this defined query by the name after the `%%sql --name pops` declaration (\"pops\" in this case). We can fire off the query and print the results like so:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bq.query(pops, {'samples_table': samples_table}).results()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to further analyze our query results locally within the IPython notebook, let's convert the result set into a [Pandas dataframe](http://pandas.pydata.org/pandas-docs/dev/generated/pandas.DataFrame.html):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pops_df = bq.query(pops, {'samples_table': samples_table}).to_dataframe()\n",
      "pops_df[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pandas dataframes have a [`dataframe.plot()`](http://pandas.pydata.org/pandas-docs/dev/generated/pandas.DataFrame.plot.html?highlight=dataframe.plot#pandas.DataFrame.plot) method that allows us to quickly render a number of standard visualizations. Let's draw a bar chart of the per-population sample counts:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import seaborn as sns\n",
      "pops_df.plot(kind='bar', y='population_count')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we have a dataframe object, we can compute arbitrary rollups and aggregations locally. For example, let's aggregate the count of samples from the population level to the super population level. We'll do this via the [`dataframe.groupby`](http://pandas.pydata.org/pandas-docs/dev/generated/pandas.DataFrame.groupby.html?highlight=groupby#pandas.DataFrame.groupby) operation, which is generally of the form: \n",
      "\n",
      "```dataframe.groupby(\"column name\").aggregation_func()```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "superpop_df = pops_df.groupby('super_population').sum()\n",
      "superpop_df.plot(kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We see that the distribution of genome samples across population and super population is relatively uniform, the exception being the AFR (African) super population."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Genome sample metrics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's explore a few quantitative attributes of the genomic samples. We'll keep our super population sample classification, but also add some metrics around the extent to which given samples were sequenced, for exomic and low coverage regions. We'll further annotate our samples with a tag for the laboratory/center that produced performed the sequencing."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%sql --name  metrics\n",
      "select \n",
      "    super_population\n",
      "    , total_lc_sequence -- lc=low coverage\n",
      "    , total_exome_sequence\n",
      "    , Main_Project_E_Centers\n",
      "from $samples_table\n",
      "where \n",
      "    total_exome_sequence is not null\n",
      "    and total_lc_sequence is not null\n",
      "    and Main_Project_E_Centers is not null\n",
      "    and Main_Project_E_Centers != 'BCM,BGI' -- remove this single outlier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Again, we can convert these results to a Pandas dataframe for local analysis and visualization"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = bq.query(metrics, {'samples_table': samples_table}).to_dataframe()\n",
      "df[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To get a feel for the quantitative sample attributes, let's see how their values are distributed among the dataset samples by plotting histograms. Note that a histogram of any dataframe attribute can be easily rendered with the pattern `dataframe.attribute_name.hist()`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.hist(alpha=0.5, bins=30)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What does the joint distribution of these two traits look like?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "g = sns.jointplot('total_exome_sequence', 'total_lc_sequence', df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Only a very slight positive correlation. Let's further annotate our scatter chart by rendering each mark with a color according to its super population assignment."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "g = sns.lmplot('total_exome_sequence', 'total_lc_sequence', hue='super_population', data=df, fit_reg=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, let's take the same plot as above, by facet our results based upon the genomic sequencing center that produced it to look for inter-center variability in the dataset."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "g = sns.lmplot('total_exome_sequence', 'total_lc_sequence', hue='super_population', col='Main_Project_E_Centers', col_wrap=2, data=df, fit_reg=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The WUSGC (the Genome Institute at Washington University) shows a small outlier cluster that is distinct relative to the other centers. The BCM (Baylor College of Medicine) facet appears the least variable within the exome sequencing dimension.\n",
      "\n",
      "Are there any super population trends here? We can facet our data a second time, this time by super population to dig deeper."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "g = sns.lmplot('total_exome_sequence', 'total_lc_sequence', hue='super_population', col='super_population', row='Main_Project_E_Centers', data=df, fit_reg=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With the data now faceted by super population as well as genomic center, the variability of the Broad institute data becomes more apparent. Furthermore, the outlier cluster noted earlier in the WUGSC facet appears to be primarily constituted by the EAS and AMR super populations, with no representation from the SAS super population."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Summary"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You should have the tools necessary for interacting with genomic data stored in BigQuery, be able to create curated local datasets and finally, visualize and explore your result sets."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}